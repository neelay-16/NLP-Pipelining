{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c6261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2086aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynlp = spacy.load(\"en_core_web_sm\")    #ML Model: Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30a3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Tom is playing football in the city Delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f87343",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = mynlp(text1)       #spacy by default convert any text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29839ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1b237d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2299dd255b0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2299dd24110>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2299cab70d0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2299dd9f250>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2299dda9010>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2299cab7370>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.pipeline    #By default NLP Pipeline contains all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df67da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\",\"ner\"])  #If we want to eliminate any step/layer, we do it in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141c7e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2299caba870>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2299f7fc590>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2299f81b510>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2299f81a390>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42334801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c8c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': []},\n",
       " 'attrs': {'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27105e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns       Requires   Scores      Retokenizes\n",
      "-   ---------------   -----------   --------   ---------   -----------\n",
      "0   tok2vec           doc.tensor                           False      \n",
      "                                                                      \n",
      "1   tagger            token.tag                tag_acc     False      \n",
      "                                                                      \n",
      "2   attribute_ruler                                        False      \n",
      "                                                                      \n",
      "3   lemmatizer        token.lemma              lemma_acc   False      \n",
      "\n",
      "\u001b[38;5;2mâœ” No problems found.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': []},\n",
       " 'attrs': {'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.analyze_pipes(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e570a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also create our customr NLP Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a6255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycustomnlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda843da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycustomnlp.pipeline    #as of now,our custom NLP pipeline is blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db2dec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = mycustomnlp(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3650f9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b67dd8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.tagger.Tagger at 0x2299e994770>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycustomnlp.add_pipe(\"tagger\")      #add tagging step/layer.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad7044c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.tagger.Tagger at 0x2299e994770>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycustomnlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c0dd3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These tagging,lemmatizing,ner are known as the components of NLP Pipelining. It can also be known as function as we did some practicals in these. And maybe there are not so much pre created components/functions which we need in our use case. So, we can create our own component/functin through pure python programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57913a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example we want to create a component which will recognize if there is a digit in the given text or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bf7a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = 'My roll number is 71'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0c98b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"mydigitcomp\")    #annotation concept in programming language\n",
    "def mydigit():\n",
    "    for word in text2.split():\n",
    "        if word.isdigit():\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e266d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to add this new custom component made by us in the NLP Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf7e4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "541a4371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.mydigit()>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.add_pipe(\"mydigitcomp\",first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0e924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mydigitcomp', <function __main__.mydigit()>),\n",
       " ('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2299caba870>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2299f7fc590>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2299f81b510>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2299f81a390>)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae794144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ecd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(doc2)     #These all are known as the attributes which we can apply on our text. But it may be the case that spacy doesn't know some other operations which we want to perform on our text, which generates the need of creating our custom attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c9deb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tom is playing football in the city Delhi"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85837b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"I am doing my career as a job in LW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb4dec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynlp = spacy.load(\"en_core_web_sm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c443117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = mynlp(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d969c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNP'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[9].tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91c87053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5efcf7bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'is_company'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc3[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mis_company\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'is_company'"
     ]
    }
   ],
   "source": [
    "doc3[9].is_company    #Let's say we want to create our new attribute as is_company, which spacy is not aware of as of now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a15a821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This process of adding/creating a custom attribute is known a token extension. Hence, we are registering a new token extension attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ff57a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9abecbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension(\"is_company\",default=False)     #By default, our new attribute will have a false value on every token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c559d0c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'is_company'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m doc3[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mis_company \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'is_company'"
     ]
    }
   ],
   "source": [
    "doc3[9].is_company = True    #But we want to set the value of this new attribute to be True on the 9th index number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6325d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But, still it says that spacy doesn't have any attribute known as is_company.It is because, if you do dir(doc3), you will be able to see that any attribute/extension which spacy already has, it is a part of some special variable. Its ._ in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4d3e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3[9]._.is_company = True    #So, we will use our newly created attribute/extension in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "474b9cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I  :  False\n",
      "am  :  False\n",
      "doing  :  False\n",
      "my  :  False\n",
      "career  :  False\n",
      "as  :  False\n",
      "a  :  False\n",
      "job  :  False\n",
      "in  :  False\n",
      "LW  :  True\n"
     ]
    }
   ],
   "source": [
    "for i in doc3:\n",
    "    print(i, \" : \",i._.is_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a10d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
